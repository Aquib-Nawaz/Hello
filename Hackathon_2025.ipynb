{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JEREvN0vArab"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aquib-Nawaz/Hello/blob/master/Hackathon_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Libraries and load key"
      ],
      "metadata": {
        "id": "yW2n_P_lfYog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U python-dotenv langchain_mistralai google-generativeai langchain langchain-groq faiss-cpu milvus pymilvus unstructured tiktoken lark langchain-community langchain-google-genai langgraph pandas pypdf PyMuPdf"
      ],
      "metadata": {
        "id": "V_yPKCnBr2t-",
        "outputId": "bcc7817f-b360-4618-a220-b4de11c3e571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain_mistralai\n",
            "  Downloading langchain_mistralai-0.2.9-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting milvus\n",
            "  Downloading milvus-2.3.5-py3-none-manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lark\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting PyMuPdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.3.47)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.21.1)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.28.1)\n",
            "Collecting httpx-sse<1,>=0.3.1 (from langchain_mistralai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (2.10.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (75.1.0)\n",
            "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/ujson/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting milvus-lite>=2.4.0 (from pymilvus)\n",
            "  Downloading milvus_lite-2.4.12-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.31.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.59-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain_mistralai) (0.29.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2025.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_mistralai-0.2.9-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_groq-0.3.1-py3-none-any.whl (15 kB)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading milvus-2.3.5-py3-none-manylinux2014_x86_64.whl (57.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymilvus-2.5.6-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.20-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.7-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.59-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading milvus_lite-2.4.12-py3-none-manylinux2014_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.31.3-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.8/175.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: langdetect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv( './.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8evVVryrAvx",
        "outputId": "a4cbc00c-0c06-4b13-86c6-fa0c3b742040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Gemini API key: \")\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")\n",
        "# os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")\n",
        "\n",
        "os.environ[\"MISTRAL_API_KEY\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "13JZ2A-wsBbw",
        "outputId": "054657b7-6626-4188-e310-e9cd07c8c69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n",
            "Enter your Gemini API key: ··········\n",
            "Enter your Mistral API key: ··········\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lE2CXz8GNq8KARLU2ONq0rxF0IdvdGOm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trying something"
      ],
      "metadata": {
        "id": "oe1gKrxCTL2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as Soup\n",
        "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "import requests\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "url = \"https://www.federalreserve.gov/apps/reportingforms/Download/DownloadAttachment?guid=83c6e71a-86c2-40b6-a9a5-16e15ca7d2d8\"\n",
        "\n",
        "\n",
        "loader = PyPDFLoader(url)\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "\n",
        "# Sort the list based on the URLs and get the text\n",
        "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
        "    data[i].page_content for i in range(len(data))\n",
        ")\n"
      ],
      "metadata": {
        "id": "TP9UVG2FUHkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "### Anthropic\n",
        "\n",
        "# Data model\n",
        "class code(BaseModel):\n",
        "    \"\"\"Schema for code solutions to questions about LCEL.\"\"\"\n",
        "\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")\n",
        "\n",
        "# LLM\n",
        "# expt_llm = \"claude-3-opus-20240229\"\n",
        "# llm = ChatGroq(\n",
        "#     model=\"llama3-70b-8192\",\n",
        "# )\n",
        "\n",
        "def parse_output(solution):\n",
        "    \"\"\"When we add 'include_raw=True' to structured output,\n",
        "    it will return a dict w 'raw', 'parsed', 'parsing_error'.\"\"\"\n",
        "\n",
        "    return solution[\"parsed\"]\n",
        "\n",
        "# Optional: Check for errors in case tool use is flaky\n",
        "def check_claude_output(tool_output):\n",
        "    \"\"\"Check for parse error or failure to call the tool\"\"\"\n",
        "\n",
        "    # Error with parsing\n",
        "    if tool_output[\"parsing_error\"]:\n",
        "        # Report back output and parsing errors\n",
        "        print(\"Parsing error!\")\n",
        "        raw_output = str(tool_output[\"raw\"].content)\n",
        "        error = tool_output[\"parsing_error\"]\n",
        "        raise ValueError(\n",
        "            f\"Error parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
        "        )\n",
        "\n",
        "    # Tool was not invoked\n",
        "    elif not tool_output[\"parsed\"]:\n",
        "        print(\"Failed to invoke tool!\")\n",
        "        raise ValueError(\n",
        "            \"You did not use the provided tool! Be sure to invoke the tool to structure the output.\"\n",
        "        )\n",
        "    return tool_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert_errors(inputs):\n",
        "    \"\"\"Insert errors for tool parsing in the messages\"\"\"\n",
        "\n",
        "    # Get errors\n",
        "    error = inputs[\"error\"]\n",
        "    messages = inputs[\"messages\"]\n",
        "    messages += [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"Retry. You are required to fix the parsing errors: {error} \\n\\n You must invoke the provided tool.\",\n",
        "        )\n",
        "    ]\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"context\": inputs[\"context\"],\n",
        "    }\n",
        "def create_code_gen_chain(){\n",
        "\n",
        "    # Prompt to enforce tool use\n",
        "    code_gen_prompt_claude = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"<instructions> You are a coding assistant with expertise in python, you are provided with import statement\n",
        "                and function definition, you will also be provided with error message\n",
        "                you are supposed to solve the error. For module not found error you are supposed\n",
        "                to add code which will install relevant module. Remember don't add any main method.</instructions>\"\"\",\n",
        "            ),\n",
        "            (\"placeholder\", \"{messages}\"),\n",
        "        ]\n",
        "    )\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "    structured_llm_claude = llm.with_structured_output(code, include_raw=True)\n",
        "    # Chain with output check\n",
        "    # code_chain_claude_raw = (\n",
        "    #     code_gen_prompt_claude | structured_llm_claude | check_claude_output\n",
        "    # )\n",
        "    code_gen_chain = code_gen_prompt_claude | structured_llm_claude | parse_output\n",
        "    return code_gen_chain\n",
        "}\n",
        "# No re-try\n",
        "\n",
        "code_gen_chain = create_code_gen_chain()"
      ],
      "metadata": {
        "id": "OExVXLW3Xbwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        error : Binary flag for control flow to indicate whether test error was tripped\n",
        "        messages : With user question, error messages, reasoning\n",
        "        generation : Code solution\n",
        "        iterations : Number of tries\n",
        "    \"\"\"\n",
        "\n",
        "    error: str\n",
        "    messages: List\n",
        "    generation: str\n",
        "    iterations: int"
      ],
      "metadata": {
        "id": "McNUAyr4WvpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Parameter\n",
        "\n",
        "# # Max tries\n",
        "\n",
        "\n",
        "### Nodes\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "def generate(state: GraphState):\n",
        "    \"\"\"\n",
        "    Generate a code solution\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATING CODE SOLUTION---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "    error = state[\"error\"]\n",
        "\n",
        "    # We have been routed back to generation with an error\n",
        "    if error == \"yes\":\n",
        "        messages += [\n",
        "            (\n",
        "                \"user\",\n",
        "                \"Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:\",\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    # Solution\n",
        "    code_solution = code_gen_chain.invoke(\n",
        "        {\"context\": concatenated_content, \"messages\": messages}\n",
        "    )\n",
        "    messages += [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Increment\n",
        "    iterations = iterations + 1\n",
        "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
        "\n",
        "\n",
        "def code_check(state: GraphState, config: RunnableConfig):\n",
        "    \"\"\"\n",
        "    Check code\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECKING CODE---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    code_solution = state[\"generation\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "    # Get solution components\n",
        "    imports = code_solution.imports\n",
        "    code = code_solution.code\n",
        "\n",
        "    # Check imports\n",
        "    try:\n",
        "        exec(imports)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
        "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
        "        messages += error_message\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": messages,\n",
        "            \"iterations\": iterations,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "\n",
        "    # Check execution\n",
        "    try:\n",
        "        exec(imports + \"\\n\" + code)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
        "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
        "        messages += error_message\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": messages,\n",
        "            \"iterations\": iterations,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "\n",
        "    # No errors\n",
        "    print(\"---NO CODE TEST FAILURES---\")\n",
        "    return {\n",
        "        \"generation\": code_solution,\n",
        "        \"messages\": messages,\n",
        "        \"iterations\": iterations,\n",
        "        \"error\": \"no\",\n",
        "    }\n",
        "\n",
        "\n",
        "def reflect(state: GraphState):\n",
        "    \"\"\"\n",
        "    Reflect on errors\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATING CODE SOLUTION---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "    code_solution = state[\"generation\"]\n",
        "\n",
        "    # Prompt reflection\n",
        "\n",
        "    # Add reflection\n",
        "    reflections = code_gen_chain.invoke(\n",
        "        {\"context\": concatenated_content, \"messages\": messages}\n",
        "    )\n",
        "    messages += [(\"assistant\", f\"Here are reflections on the error: {reflections}\")]\n",
        "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
        "\n",
        "\n",
        "### Edges\n",
        "\n",
        "\n",
        "def decide_to_finish(state: GraphState):\n",
        "    \"\"\"\n",
        "    Determines whether to finish.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "    max_iterations = 3\n",
        "    # Reflect\n",
        "    # flag = 'reflect'\n",
        "    flag = \"do not reflect\"\n",
        "    error = state[\"error\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "    if error == \"no\" or iterations == max_iterations:\n",
        "        print(\"---DECISION: FINISH---\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
        "        if flag == \"reflect\":\n",
        "            return \"reflect\"\n",
        "        else:\n",
        "            return \"generate\""
      ],
      "metadata": {
        "id": "pG1__Ydc4YmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "\n",
        "def create_code_gen_graph():\n",
        "\n",
        "    workflow = StateGraph(GraphState)\n",
        "\n",
        "    # Define the nodes\n",
        "    workflow.add_node(\"generate\", generate)  # generation solution\n",
        "    workflow.add_node(\"check_code\", code_check)  # check code\n",
        "    workflow.add_node(\"reflect\", reflect)  # reflect\n",
        "\n",
        "    # Build graph\n",
        "    workflow.add_edge(START, \"check_code\")\n",
        "    workflow.add_edge(\"generate\", \"check_code\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"check_code\",\n",
        "        decide_to_finish,\n",
        "        {\n",
        "            \"end\": END,\n",
        "            \"reflect\": \"reflect\",\n",
        "            \"generate\": \"generate\",\n",
        "        },\n",
        "    )\n",
        "    workflow.add_edge(\"reflect\", \"generate\")\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "nwueSEKM4hiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "app = create_code_gen_graph()\n",
        "\n",
        "config = {\"configurable\":{\"model\": model, \"concatenated_content\":[]}}\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "nEp2cQec5cZF",
        "outputId": "6c22bc73-ecda-41e3-a1f0-0ea70cc73ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How can I directly pass a string to a runnable and use it to construct the input needed for my prompt?\"\n",
        "solution = app.invoke({\"messages\": [(\"user\", question)], \"iterations\": 0, \"error\": \"\"}, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6VCrBcK7NH6",
        "outputId": "36e85907-1700-48b5-9751-70ccc74a1498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "---CODE BLOCK CHECK: FAILED---\n",
            "---DECISION: RE-TRY SOLUTION---\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "---CODE BLOCK CHECK: FAILED---\n",
            "---DECISION: RE-TRY SOLUTION---\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "---CODE BLOCK CHECK: FAILED---\n",
            "---DECISION: FINISH---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generated code"
      ],
      "metadata": {
        "id": "JEREvN0vArab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, date, timedelta\n",
        "import logging\n",
        "import iso4217\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "LOG_FILE = 'transaction_validation.log'\n",
        "FAILED_TRANSACTIONS_FILE = 'failed_transactions.csv'\n",
        "HIGH_RISK_COUNTRIES = ['Syria', 'Iran', 'North Korea', 'Sudan']  # Example list - expand as needed\n",
        "CROSS_BORDER_THRESHOLD = 10000\n",
        "ACCEPTED_JURISDICTIONS = ['USA', 'Canada', 'UK', 'Germany', 'France'] # Example List\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "def is_valid_iso4217_currency(currency_code):\n",
        "    \"\"\"\n",
        "    Checks if a currency code is a valid ISO 4217 currency.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        iso4217.Currency(currency_code)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def validate_transaction(df):\n",
        "    \"\"\"\n",
        "    Validates transaction data against regulatory profiling instructions.\n",
        "    \"\"\"\n",
        "\n",
        "    failed_transactions = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        errors = []\n",
        "\n",
        "        # 1. Transaction Amount vs. Reported_Amount\n",
        "        transaction_amount = row['Transaction_Amount']\n",
        "        reported_amount = row['Reported_Amount']\n",
        "        if transaction_amount != reported_amount:\n",
        "            # Apply 1% deviation for cross-currency (assuming if currency != USD it's cross-currency for simplicity)\n",
        "            if row['Currency'] == 'USD':  # Example: consider USD as base currency\n",
        "                if abs(transaction_amount - reported_amount) > 0.01 * max(transaction_amount, reported_amount):\n",
        "                    errors.append(\n",
        "                        \"Transaction Amount and Reported Amount do not match (no cross-currency deviation allowed).\"\n",
        "                        f\" Transaction Amount: {transaction_amount}, Reported Amount: {reported_amount}. \"\n",
        "                        \"Remediation: Investigate the discrepancy and correct the Reported Amount.\"\n",
        "                    )\n",
        "            else:\n",
        "                deviation = abs(transaction_amount - reported_amount) / max(transaction_amount, reported_amount)\n",
        "                if deviation > 0.01:\n",
        "                    errors.append(\n",
        "                        \"Transaction Amount and Reported Amount do not match, exceeding 1% deviation allowed for \"\n",
        "                        \"cross-currency transactions.\"\n",
        "                        f\" Transaction Amount: {transaction_amount}, Reported Amount: {reported_amount}. \"\n",
        "                        \"Remediation: Verify exchange rate and correct the Reported Amount if needed.\"\n",
        "                    )\n",
        "\n",
        "        # 2. Account Balance Validation\n",
        "        account_balance = row['Account_Balance']\n",
        "        if account_balance < 0 and not isinstance(row['Risk_Source'], str) and 'OD' not in row['Risk_Source']:  #Assuming Risk_Source can contain 'OD' if it's overdraft\n",
        "\n",
        "            errors.append(\n",
        "                \"Account Balance is negative for a non-overdraft account.\"\n",
        "                f\" Account Balance: {account_balance}. \"\n",
        "                \"Remediation: Review the account type and balance; correct if necessary or flag as Overdraft.\"\n",
        "            )\n",
        "\n",
        "        # 3. Currency Code Validation\n",
        "        currency = row['Currency']\n",
        "        if not is_valid_iso4217_currency(currency):\n",
        "            errors.append(\n",
        "                f\"Invalid Currency Code: {currency}. Remediation: Correct the currency code to a valid ISO 4217 \"\n",
        "                \"currency code.\"\n",
        "            )\n",
        "\n",
        "        # 4. Cross-Border Transaction Limits (Simplified - needs real limit data)\n",
        "        # Assume all transactions to countries other than 'USA' are cross-border.\n",
        "        country = row['Country']\n",
        "        if country != 'USA': #Example\n",
        "           #Placeholder for real limit lookup logic\n",
        "           pass\n",
        "           #Implement Regulatory Lookup for country and currency\n",
        "           #Example:  if row['Transaction_Amount'] > LIMIT: errors.append(\"Cross-Border Limit Exceeded\")\n",
        "\n",
        "        # 5. Country Jurisdiction Check\n",
        "        if row['Country'] not in ACCEPTED_JURISDICTIONS:\n",
        "            errors.append(\n",
        "                f\"Invalid Jurisdiction: {row['Country']}. Remediation: Update the Country field with an accepted \"\n",
        "                \"jurisdiction.\"\n",
        "            )\n",
        "\n",
        "        # 6. Cross-Border Transaction Remarks\n",
        "        if country != 'USA' and transaction_amount > CROSS_BORDER_THRESHOLD and (not isinstance(row['Risk_Source'], str) or len(row['Risk_Source']) == 0):\n",
        "            errors.append(\n",
        "                \"Missing transaction remarks for a cross-border transaction exceeding \"\n",
        "                f\"${CROSS_BORDER_THRESHOLD}. Remediation: Add mandatory transaction remarks.\"\n",
        "            )\n",
        "\n",
        "        # 7. Transaction Date Validation\n",
        "        transaction_date = pd.to_datetime(row['Transaction_Date'])\n",
        "        today = date.today()\n",
        "        age = today - transaction_date.date()\n",
        "\n",
        "        if transaction_date.date() > today:\n",
        "            errors.append(\n",
        "                \"Transaction Date is in the future.\"\n",
        "                f\" Transaction Date: {transaction_date.date()}. Remediation: Correct the Transaction Date.\"\n",
        "            )\n",
        "        elif age > timedelta(days=365):\n",
        "            logging.warning(f\"Old Transaction Date detected: {transaction_date.date()}. Requires further review.\")\n",
        "\n",
        "        # 8. High-Risk Transaction Flagging\n",
        "        if transaction_amount > 5000 and (country in HIGH_RISK_COUNTRIES):\n",
        "            logging.warning(\n",
        "                f\"High-Risk Transaction detected: Amount: {transaction_amount}, Country: {country}. Requires an \"\n",
        "                \"automatic compliance check.\"\n",
        "            )\n",
        "\n",
        "        # 9. Round-Number Transaction Analysis\n",
        "        if transaction_amount % 1000 == 0:  # Example: Checking for multiples of 1000\n",
        "            logging.warning(\n",
        "                f\"Round-Number Transaction detected: Amount: {transaction_amount}. Requires additional validation \"\n",
        "                \"steps for potential money laundering risks.\"\n",
        "            )\n",
        "        if errors:\n",
        "            failed_transactions.append({**row.to_dict(), 'errors': errors})\n",
        "            logging.error(f\"Transaction failed validation: {row['Customer_Id']} - {errors}\")\n",
        "\n",
        "\n",
        "    # Convert failed transactions to DataFrame and save to CSV\n",
        "    if failed_transactions:\n",
        "        failed_transactions_df = pd.DataFrame(failed_transactions)\n",
        "\n",
        "        # Check if file exists, append if it does, create if it doesn't\n",
        "        if os.path.exists(FAILED_TRANSACTIONS_FILE):\n",
        "            failed_transactions_df.to_csv(FAILED_TRANSACTIONS_FILE, mode='a', header=False, index=False)\n",
        "        else:\n",
        "            failed_transactions_df.to_csv(FAILED_TRANSACTIONS_FILE, header=True, index=False)\n",
        "\n",
        "    return failed_transactions  # Returning failed transactions for potential further processing\n",
        "\n",
        "# Example Usage:\n",
        "if __name__ == '__main__':\n",
        "    # Create a dummy CSV file for testing\n",
        "    data = {\n",
        "        'Customer_Id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "        'Account_Balance': [1000, -500, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000],\n",
        "        'Transaction_Amount': [100, 50, 200, 300, 6000, 5000, 1000, 5000, 1000, 5000],\n",
        "        'Reported_Amount': [100, 50, 200, 300, 6001, 5050, 1000, 5000, 999, 5000],\n",
        "        'Currency': ['USD', 'USD', 'EUR', 'GBP', 'USD', 'USD', 'USD', 'USD', 'USD', 'USD'],\n",
        "        'Country': ['USA', 'Canada', 'UK', 'Germany', 'Syria', 'USA', 'USA', 'USA', 'USA', 'USA'],\n",
        "        'Transaction_Date': ['2023-10-26', '2024-11-15', '2023-01-01', '2025-01-01', '2023-11-15', '2023-11-15',\n",
        "                             '2023-11-15', '2023-11-15', '2023-11-15', '2023-11-15'],\n",
        "        'Risk_Source': ['', 'OD', '', '', '', '', '', '', '', ''] #Blank and \"OD\" examples\n",
        "    }\n",
        "    dummy_df = pd.DataFrame(data)\n",
        "    dummy_df.to_csv('transactions.csv', index=False)\n",
        "\n",
        "    # Read the CSV file\n",
        "    try:\n",
        "        transactions_df = pd.read_csv('transactions.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: transactions.csv not found.  Please create it or adjust the file path.\")\n",
        "        exit()\n",
        "\n",
        "    # Validate the transactions\n",
        "    failed = validate_transaction(transactions_df)\n",
        "\n",
        "    if failed:\n",
        "        print(f\"Validation complete. Failed transactions written to {FAILED_TRANSACTIONS_FILE}\")\n",
        "    else:\n",
        "        print(\"All transactions passed validation.\")\n",
        "\n",
        "    print(f\"Validation log written to {LOG_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ6Jr6BwykNN",
        "outputId": "5171cb9e-9c27-4300-c72a-971ae69a49ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Old Transaction Date detected: 2023-10-26. Requires further review.\n",
            "WARNING:root:Old Transaction Date detected: 2023-01-01. Requires further review.\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:High-Risk Transaction detected: Amount: 6000, Country: Syria. Requires an automatic compliance check.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 6000. Requires additional validation steps for potential money laundering risks.\n",
            "ERROR:root:Transaction failed validation: 5 - ['Invalid Jurisdiction: Syria. Remediation: Update the Country field with an accepted jurisdiction.']\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 5000. Requires additional validation steps for potential money laundering risks.\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 1000. Requires additional validation steps for potential money laundering risks.\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 5000. Requires additional validation steps for potential money laundering risks.\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 1000. Requires additional validation steps for potential money laundering risks.\n",
            "WARNING:root:Old Transaction Date detected: 2023-11-15. Requires further review.\n",
            "WARNING:root:Round-Number Transaction detected: Amount: 5000. Requires additional validation steps for potential money laundering risks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation complete. Failed transactions written to failed_transactions.csv\n",
            "Validation log written to transaction_validation.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChatGPT HElp"
      ],
      "metadata": {
        "id": "IPgPSmQ0hYps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://www.federalreserve.gov/apps/reportingforms/Download/DownloadAttachment?guid=83c6e71a-86c2-40b6-a9a5-16e15ca7d2d8\" --output regulatory.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOA_c-3AifRv",
        "outputId": "c6a7c51b-8837-4018-faa2-30b029b2cebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2549k  100 2549k    0     0  3138k      0 --:--:-- --:--:-- --:--:-- 3136k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import re\n",
        "\n",
        "# Load PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Extract tables (Example using Pandas for structured tables)\n",
        "def extract_table_rows_from_pdf(pdf_path):\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    table_rows = []\n",
        "    for page in doc:\n",
        "        tables = page.find_tables()\n",
        "        for table in tables:\n",
        "            df = table.to_pandas()\n",
        "\n",
        "            # Convert each row into a structured text chunk\n",
        "            for _, row in df.iterrows():\n",
        "                row_text = \" | \".join(f\"{col}: {str(value)}\" for col, value in row.items())\n",
        "                table_rows.append(Document(page_content=(row_text), metadata={\"source\": \"table\"}))\n",
        "\n",
        "            # Create a document for each chunk\n",
        "    return table_rows\n",
        "\n",
        "def extract_definitions(text):\n",
        "    \"\"\"Find definitions in the document. Adjust regex based on document format.\"\"\"\n",
        "    definition_pattern = r\"(\\b[A-Z][a-zA-Z\\s]+\\b)[:\\-]\\s*(.*?)\\n\"\n",
        "    matches = re.findall(definition_pattern, text)\n",
        "\n",
        "    definitions = {term.strip(): definition.strip() for term, definition in matches}\n",
        "    return definitions\n",
        "\n",
        "\n",
        "def initializeVectorStore(pdf_path, folder_path):\n",
        "    try:\n",
        "        embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        return FAISS.load_local(folder_path, embedding_model, allow_dangerous_deserialization = True)\n",
        "    except:\n",
        "        raw_text = extract_text_from_pdf(pdf_path)\n",
        "        tables_data = extract_table_rows_from_pdf(pdf_path)\n",
        "\n",
        "        # Split text into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "        chunks = text_splitter.split_text(raw_text)\n",
        "        docs = [Document(page_content=chunk, metadata={\"source\": \"text\"}) for chunk in chunks]\n",
        "        embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        merged_doc = docs + tables_data\n",
        "        vectorstore = FAISS.from_documents(merged_doc, embedding_model)\n",
        "        # Save the vector store\n",
        "        vectorstore.save_local(folder_path)\n",
        "        return vectorstore\n"
      ],
      "metadata": {
        "id": "hcN85DuIqBay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_columns(pdf_path):\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    table_rows = []\n",
        "    data = []\n",
        "    for page in doc[166:219]:\n",
        "        tables = page.find_tables()\n",
        "        for table in tables:\n",
        "            df = table.to_pandas()\n",
        "\n",
        "            # Convert each row into a structured text chunk\n",
        "            table_data = []\n",
        "            for _, row in df.iterrows():\n",
        "                strin = re.sub('\\\\s+','' , row.iloc[1])\n",
        "                if strin:\n",
        "                  data.append(strin)\n",
        "                # row_text = \" | \".join(f\"{col}: {str(value)}\" for col, value in row.items())\n",
        "                # data.append(row_text)\n",
        "\n",
        "    for i,x in enumerate(data):\n",
        "      mg = re.findall(r\"\\(([^)]*)\\)$\", x)\n",
        "      if mg:\n",
        "          data[i] = re.sub(r\"\\)\",'',mg[-1])\n",
        "    with open('temp.txt', 'w') as f:\n",
        "      f.write('\\n'.join(data))\n",
        "extract_columns(\"regulatory.pdf\")"
      ],
      "metadata": {
        "id": "ujbv2sQtVAY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf regulatory_db\n",
        "vecstore = initializeVectorStore(\"regulatory.pdf\", \"regulatory_db\")"
      ],
      "metadata": {
        "id": "B4i_BzISoY6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "\n",
        "def get_user_id(config: RunnableConfig) -> str:\n",
        "    user_id = config[\"configurable\"].get(\"user_id\")\n",
        "    if user_id is None:\n",
        "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
        "\n",
        "    return user_id\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnP44h5CshNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getVectorStore(dbfolder):\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    return FAISS.load_local(dbfolder, embedding_model, allow_dangerous_deserialization = True)"
      ],
      "metadata": {
        "id": "gm_nQUwMvsjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "chatbot_main_template_str = \"\"\"\n",
        "You are a compliance assistant helping auditor in creating\n",
        "    profiling rule for bank transaction data based on regulatory reporting instructions.\n",
        "    Based on question you have to answer providing profiling rules for the columns provided by user:\n",
        "    You can access chat history by calling search_recall_memories tool similarly you can save important\n",
        "    context in history by calling save_recall_memory\n",
        "    You can also access to federal reserve bank regulatory reporting instruction by calling search_document_context tool\n",
        "    You should not tell user what you are doing.\n",
        "    Apart from these you will not be provided with anything else any extra context\n",
        "    you need call search_document_context tool\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "chatbot_contextualize_query_template_str = \"\"\"\n",
        "            You are a helpful assistant that contextualizes the user query depending on the previous conversation\n",
        "                    queries only if required\n",
        "            Given a chat history and the latest user question \\\n",
        "            which might reference context in the chat history, formulate a standalone question \\\n",
        "            which can be understood without the chat history. Do NOT answer the question, \\\n",
        "            just reformulate it if and only if needed and otherwise return it as is. \\\n",
        "            History: {history}\n",
        "            Latest query: {query}\n",
        "\n",
        "            ANSWER: \"\"\"\n",
        "def get_chatbot_maintemplate():\n",
        "    return PromptTemplate(template=chatbot_main_template_str, input_variables=[ \"question\"])\n",
        "\n",
        "def get_chatbot_contextualizequery_template():\n",
        "    return PromptTemplate(template=chatbot_main_template_str, input_variables=[\"history\", \"query\"])\n",
        "@tool\n",
        "def save_recall_memory(memory: str) -> str:\n",
        "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
        "    # user_id = get_user_id(config)\n",
        "    document = Document(\n",
        "        page_content=memory,metadata={\"source\":\"history\"} ,id=str(uuid.uuid4())#, metadata={\"user_id\": user_id}\n",
        "    )\n",
        "    vecstore.add_documents([document])\n",
        "    return memory\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_recall_memories( query: str) -> List[str]:\n",
        "    \"\"\"Search for relevant memories.\"\"\"\n",
        "    # user_id = get_user_id(config)\n",
        "\n",
        "    def _filter_function(doc: Document) -> bool:\n",
        "        return doc.metadata.get(\"source\") == \"history\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=3, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n",
        "\n",
        "@tool\n",
        "def search_document_context( query: str) -> List[str]:\n",
        "    \"\"\"Search for relevant context from documents.\"\"\"\n",
        "    def _filter_function(doc: Document) -> bool:\n",
        "        return doc.metadata.get(\"source\") != \"history\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=3, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n"
      ],
      "metadata": {
        "id": "EqUsjEPkCX6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import List, TypedDict\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_core.tools import tool, Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# from prompts import get_chatbot_maintemplate, get_chatbot_contextualizequery_template\n",
        "# from vectorstore import getVectorStore\n",
        "\n",
        "\n",
        "\n",
        "# Extend the state to include chat_history\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "    chat_history: List[str]\n",
        "\n",
        "class MyChatBot:\n",
        "    def __init__(self):\n",
        "        self.chat_history = []\n",
        "        self.vectorstore = getVectorStore(\"regulatory_db\")\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "        self.main_prompt = get_chatbot_maintemplate()\n",
        "        self.history_contextualize_prompt = get_chatbot_contextualizequery_template()\n",
        "        self.boundagent = self.llm.bind_tools([\n",
        "            save_recall_memory, search_document_context, search_recall_memories])\n",
        "\n",
        "    # Application Step 1: Retrieve relevant documents\n",
        "    def retrieve(self, question) -> dict:\n",
        "        # Retrieve documents based on similarity search using the question\n",
        "        self.chat_history += [f\"user: {question}\"]\n",
        "        contextualized_query = self.contextualize_query(question)\n",
        "        retrieved_docs = self.vectorstore.similarity_search(contextualized_query)\n",
        "\n",
        "        return {\"context\": retrieved_docs, \"question\": contextualized_query}\n",
        "\n",
        "    def contextualize_query(self, query: str):\n",
        "        \"\"\"\n",
        "        Contextualizes the user query based on the conversation history.\n",
        "        :param query:   The user query\n",
        "        :param history:    The conversation history\n",
        "        :return:   The contextualized query\n",
        "        \"\"\"\n",
        "        try:\n",
        "            message = self.history_contextualize_prompt.invoke({\"history\": self.chat_history, \"query\":query})\n",
        "            response = self.llm.invoke(message)\n",
        "\n",
        "            return str(response.content)\n",
        "        except Exception as e:\n",
        "            print(f\"Error contextualizing query: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    # Application Step 2: Generate an answer using the retrieved context and chat history\n",
        "    def generate(self, query:str):\n",
        "        # Concatenate the page_content of each document into a single context string\n",
        "        # state = self.retrieve(query)\n",
        "        # docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "\n",
        "        # Build messages using a prompt template including question, docs_content, and chat_history_text\n",
        "        messages = self.main_prompt.invoke({\n",
        "            \"question\": query,\n",
        "#            \"context\": docs_content,\n",
        "        })\n",
        "\n",
        "\n",
        "        # Generate a response using the LLM\n",
        "        response = self.boundagent.invoke(messages)\n",
        "\n",
        "        # Append the new conversation turn to the chat history\n",
        "        new_turn = f\"assistant: {response.content}\"\n",
        "        self.chat_history += [new_turn]\n",
        "\n",
        "        return response.content\n",
        "\n",
        "        # user_id = get_user_id(config\n",
        "\n",
        "# # Compile application graph: sequence of steps with state propagation\n",
        "# graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "# graph_builder.add_edge(START, \"retrieve\")\n",
        "# graph = graph_builder.compile()\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "Ep12wH-eBzvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = MyChatBot()\n",
        "while True:\n",
        "    # Read user input\n",
        "    user_question = input(\"Compliance Officer: \")\n",
        "    if user_question.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    response = chatbot.generate(user_question)\n",
        "\n",
        "    # Display the generated answer\n",
        "    print(\"\\n🔹 Chatbot:\", response)\n",
        "\n",
        "    # Update the chat history with the new conversation turn\n",
        "    # Each turn is recorded as \"Q: <question>\\nA: <answer>\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "TaRW0_61h744",
        "outputId": "c1273d22-b76d-4c93-96fd-48e6b2d76cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compliance Officer: Hi there can you tell me what are most important field in loan schedule accordin to document\n",
            "\n",
            "🔹 Chatbot: \n",
            "Compliance Officer: Why are you silent\n",
            "\n",
            "🔹 Chatbot: I am ready to assist with profiling rules for bank transaction data based on regulatory reporting instructions. How may I help you today?\n",
            "Compliance Officer: Write on eprofiling rule\n",
            "\n",
            "🔹 Chatbot: Please provide the column names for which you want me to create profiling rules. I need to know the columns in the bank transaction data to provide relevant and accurate rules.\n",
            "Compliance Officer: StockExchange\n",
            "\n",
            "🔹 Chatbot: \n",
            "Compliance Officer: Summarize our chat\n",
            "\n",
            "🔹 Chatbot: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1d7d7bf44298>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Read user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0muser_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Compliance Officer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_question\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#memgpt"
      ],
      "metadata": {
        "id": "lLOw6kYzkHuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "# Data model\n",
        "class Code(BaseModel):\n",
        "    \"\"\"Schema for validation function.\"\"\"\n",
        "\n",
        "    imports: Optional[str] = Field(..., description=\"import and function\")\n",
        "    body:  Optional[str] = Field(..., description=\"Function\")\n",
        "    testing:  Optional[str] = Field(..., description=\"This code is used to test function will \"\n",
        "    \"be used just to test if your code is correct\")\n",
        "\n",
        "class ValidationRule(BaseModel):\n",
        "    \"\"\"Use this tool to send final message to user\"\"\"\n",
        "    error_message: str = Field(..., description=\"Brief error message\")\n",
        "    field_name: str = Field(..., description=\"field name\")\n",
        "    validation_function_name: str = Field(..., description=\"Function name as defined in prompt\")\n",
        "    arguments: List[Union[str, int]] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"A list of arguments for the validation function\",\n",
        "    )\n",
        "    # code: Optional[str] = Field(None, description=\"import statement and function without any main method. This function will be used later by main method\")\n",
        "\n",
        "class ComplianceResponse(BaseModel):\n",
        "    \"\"\"Respond to the user with this\"\"\"\n",
        "    extracted_rules: List[ValidationRule] = Field(..., description=\"List of extracted data validation rules\")\n"
      ],
      "metadata": {
        "id": "AvXNAw8xLivV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "\n",
        "my_rules = ComplianceResponse(extracted_rules=[])\n",
        "\n",
        "@tool\n",
        "def is_integer(field_name: str, description: Annotated[str, \"description of the rule\"])->str:\n",
        "    \"\"\"Regester integer check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name,\n",
        "                                                   description=description, validation_function_name=\n",
        "        \"is_integer\"))\n",
        "\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_integer.\"\n",
        "\n",
        "@tool\n",
        "def is_whole_number(field_name: str, description: str)->str:\n",
        "    \"\"\"Register whole number check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description = description,\n",
        "                                                    validation_function_name=\n",
        "        \"is_whole_number\"))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function  is_whole_number.\"\n",
        "\n",
        "@tool\n",
        "def is_in_range(field_name: str, description: str, min_v:int, max_v:int)->str:\n",
        "    \"\"\"Register whole number check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                    validation_function_name=\n",
        "        \"is_in_range\", arguments= [min_v, max_v]))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function  is_in_range.\"\n",
        "\n",
        "@tool\n",
        "def matches_pattern(field_name: str, description: str, pattern: List[str])->str:\n",
        "    \"\"\"Register regex pattern check \"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                    validation_function_name=\n",
        "        \"matches_pattern\", arguments= [pattern]))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function matches_pattern.\"\n",
        "\n",
        "@tool\n",
        "def is_in_list(field_name: str, description: str, allowed_values: List[str])->str:\n",
        "    \"\"\"Register is in list check\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                   validation_function_name=\n",
        "        \"is_in_list\", arguments= [allowed_values]))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_in_list.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_valid_date(field_name: str, description: str, format: str)->str:\n",
        "    \"\"\"Register is valid date format check\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description, validation_function_name=\n",
        "        \"is_valid_date\"))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_valid_date. \"\n",
        "\n",
        "registration_rules = [is_integer, is_in_list, is_whole_number, is_valid_date,\n",
        "                      matches_pattern, is_in_range]"
      ],
      "metadata": {
        "cellView": "code",
        "id": "PQ1PMnM2QoM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "import tiktoken\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.embeddings import Embeddings\n",
        "from langchain_core.messages import get_buffer_string\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_core.tools import tool, Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, START, MessagesState, StateGraph\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "kaUsj6Gtjc2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "\n",
        "def get_user_id(config: RunnableConfig) -> str:\n",
        "    user_id = config[\"configurable\"].get(\"user_id\")\n",
        "    if user_id is None:\n",
        "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
        "\n",
        "    return user_id\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_recall_memory(memory: str) -> str:\n",
        "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
        "    # user_id = get_user_id(config)\n",
        "    document = Document(\n",
        "        page_content=memory,metadata={\"source\":\"history\"} ,id=str(uuid.uuid4())#, metadata={\"user_id\": user_id}\n",
        "    )\n",
        "    vecstore.add_documents([document])\n",
        "    return memory\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_recall_memories( query: str) -> List[str]:\n",
        "    \"\"\"Search for relevant memories.\"\"\"\n",
        "    # user_id = get_user_id(config)\n",
        "\n",
        "    def _filter_function(metadata) -> bool:\n",
        "        return metadata.get(\"source\") == \"history\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=3, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n",
        "\n",
        "@tool\n",
        "def search_document_context( query: str, numberoffields: int) -> List[str]:\n",
        "    \"\"\"Search for relevant context from regulatory documents.\"\"\"\n",
        "    def _filter_function(metadata) -> bool:\n",
        "        return metadata.get(\"source\") == \"table\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=numberoffields+1, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n",
        "\n",
        "class State(MessagesState):\n",
        "    # add memories that will be retrieved based on the conversation context\n",
        "    recall_memories: List[str]\n",
        "    final_response: ComplianceResponse\n",
        "\n"
      ],
      "metadata": {
        "id": "NpleO1FZkgoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = ChatPromptTemplate.from_messages([(\n",
        "  \"system\",\n",
        "  \"\"\"\n",
        "You are an expert python developer you have vast experience in profiling data\n",
        "which are used for regulatory reporting. In this task you will be provided with column names.\n",
        "Your task is to generate code for all the validation rules pertainin to these columns\n",
        "1. You are given tool called search_document_context which can be used to extract validation requirement\n",
        "from regulatory document.\n",
        "2. You have to give special attention on allowed_values column. In most cases\n",
        "this column will be enough.\n",
        "3.Some example of allowed_values column\n",
        "a.{{Rounded whole dollar amount,\n",
        "e.g.: 20000000\n",
        "Supply numeric values without\n",
        "any non- numeric formatting\n",
        "(no dollar sign, commas or\n",
        "decimal).}} this can be interpreted as regex pattern for whole number ,\n",
        "b. Must be in yyyy- mm-dd format,e.g.: 2005-02-01:- can be interpreted\n",
        "as date validation.\n",
        "c. Similarly 2 character country code :- can be interpreted as regex pattern for city code.\n",
        "d. Enter number code of the description:- check description to find out allowable code value\n",
        " usually 1-n function will be integer range checker which takes two additional parameter of min and max\n",
        "e. one of the given 1.value 2.value1 3.value2 4.value3 so our function will take list of allowed value\n",
        "as argument and can check if it exists\n",
        "f. value must be valid code as given in description use in_range min value 1 max value x\n",
        "highest code in description\n",
        "4. You have to register each rule by calling corresponding tool description is what will be printed if the\n",
        "valdation fails example 'field x Should be integer'\n",
        "5. Remember reporting is most important so your validation rules must include nice description\n",
        "which can be used to create a informed error message for the cause of failing of rule.\n",
        "6. For now you can ignore validation rules requiring more than one field\n",
        "7. You are provided with following predefined validation functions:\n",
        "a.) def is_integer(value)\n",
        "    check if field is integer\n",
        "b.) def is_whole_number(value)\n",
        "    check if field is whole number\n",
        "c.) def matches_pattern(value,List[str]):\n",
        "    provide arguments\n",
        "    check if any of the regex pattern match\n",
        "d.) def is_in_range(value, min_val: int, max_val:int)\n",
        "    check if integer is in range\n",
        "e.) def is_in_list(value, List[str])\n",
        "    check if value is in list\n",
        "f.) def is_valid_date(value)\n",
        "    check if value is date\n",
        "Here value is the value of that row and column from csv data file. You are supposed to provide any argument apart from\n",
        "value if required.\n",
        "\n",
        "8. Don't make any assumption about the rule\n",
        "9. You can retrieve context for each column separately for better context\n",
        "10. You should call registration tool once each for each rule:\n",
        "  field_name:  field_name ,description : brief rule description\n",
        "11. You must batch your rule registration tool call so as not to exceed api limit\n",
        "12. For most of the field you have to call atleast one registration tool\n",
        "13. Please don't call tool twice for same rule and column\n",
        " Recall memories are contextually retrieved based on the current\n",
        "conversation:\\n{recall_memories}\\n\\n\n",
        "\n",
        "\"Memory Usage Guidelines:\\n\"\n",
        "            \"1. Actively use memory tools (search_recall_memories, save_recall_memory)\"\n",
        "            \" to build a comprehensive understanding of the code.\\n\"\n",
        "            \"2. Make informed suppositions and extrapolations based on stored\"\n",
        "            \" memories.\\n\"\n",
        "            \"3. Regularly reflect on past interactions to identify patterns and\"\n",
        "            \" preferences.\\n\"\n",
        "            4. Don't assume anything\n",
        "\n",
        "**Output Instruction**\n",
        "Follow following output format for ComplianceResponse tool rigorously\n",
        "{schema}\n",
        "\n",
        "\"\"\"),(\"placeholder\", \"{messages}\")]).partial(schema= ComplianceResponse.model_json_schema())"
      ],
      "metadata": {
        "id": "jCg3Y-cZRrET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_ge_prompt_with_tools_to_register_rules = ChatPromptTemplate.from_messages([(\n",
        "  \"system\",\n",
        "  \"\"\"\n",
        "You are an expert python developer you have vast experience in profiling data\n",
        "which are used for regulatory reporting. In this task you will be provided with column names.\n",
        "Your task is to generate code for all the validation rules pertainin to these columns\n",
        "1. You are given tool called search_document_context which can be used to extract validation requirement\n",
        "from regulatory document.\n",
        "2. You have to give special attention on allowed_values column. In most cases\n",
        "this column will be enough.\n",
        "3.Some example of allowed_values column\n",
        "a.{{Rounded whole dollar amount,\n",
        "e.g.: 20000000\n",
        "Supply numeric values without\n",
        "any non- numeric formatting\n",
        "(no dollar sign, commas or\n",
        "decimal).}} this can be interpreted as regex pattern for whole number ,\n",
        "b. Must be in yyyy- mm-dd format,e.g.: 2005-02-01:- can be interpreted\n",
        "as date validation.\n",
        "c. Similarly 2 character country code :- can be interpreted as regex pattern for city code.\n",
        "d. Enter number code of the description:- check description to find out allowable code value\n",
        " usually 1-n function will be integer range checker which takes two additional parameter of min and max\n",
        "e. one of the given 1.value 2.value1 3.value2 4.value3 so our function will take list of allowed value\n",
        "as argument and can check if it exists\n",
        "f. value must be valid code as given in description use in_range min value 1 max value x\n",
        "highest code in description\n",
        "4. You have to register each rule by calling corresponding tool description is what will be printed if the\n",
        "valdation fails example 'field x Should be integer'\n",
        "5. Remember reporting is most important so your validation rules must include nice description\n",
        "which can be used to create a informed error message for the cause of failing of rule.\n",
        "6. For now you can ignore validation rules requiring more than one field\n",
        "7. Please don't register any rule which is not required\n",
        "8. Don't make any assumption about the rule\n",
        "9. You can retrieve context for each column separately for better context\n",
        "10. You should call registration tool once each for each rule:\n",
        "  field_name:  field_name ,description : brief rule description\n",
        "11. You must batch your rule registration tool call so as not to exceed api limit\n",
        "12. For most of the field you have to call atleast one registration tool\n",
        "13. Please don't call tool twice for same rule and column\n",
        " Recall memories are contextually retrieved based on the current\n",
        "conversation:\\n{recall_memories}\\n\\n\n",
        "\n",
        "\"Memory Usage Guidelines:\\n\"\n",
        "            \"1. Actively use memory tools (search_recall_memories, save_recall_memory)\"\n",
        "            \" to build a comprehensive understanding of the code.\\n\"\n",
        "            \"2. Make informed suppositions and extrapolations based on stored\"\n",
        "            \" memories.\\n\"\n",
        "            \"3. Regularly reflect on past interactions to identify patterns and\"\n",
        "            \" preferences.\\n\"\n",
        "            4. Don't assume anything\n",
        "\n",
        "\"\"\"),(\"placeholder\", \"{messages}\")])"
      ],
      "metadata": {
        "id": "gkCR1v-CEO-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_memories: List[str]\n",
        "\n",
        "\n",
        "code_gen_chain_prompt = ChatPromptTemplate.from_messages([(\n",
        "  \"system\",\n",
        "  \"\"\"\n",
        "You are an expert python developer you have vast experience in profiling data\n",
        "which are used for regulatory reporting. In this task you will be provided with column names.\n",
        "Your task is to generate code for all the validation rules pertainin to these columns\n",
        "1. You are given tool called search_document_context which can be used to extract validation requirement\n",
        "from regulatory document.\n",
        "2. You have to give special attention on allowed_values column. In most cases\n",
        "this column will be enough.\n",
        "3.Some example of allowed_values column\n",
        "a.{{Rounded whole dollar amount,\n",
        "e.g.: 20000000\n",
        "Supply numeric values without\n",
        "any non- numeric formatting\n",
        "(no dollar sign, commas or\n",
        "decimal).}} this can be interpreted as regex pattern for whole number ,\n",
        "b. Must be in yyyy- mm-dd format,e.g.: 2005-02-01:- can be interpreted\n",
        "as date validation.\n",
        "c. Similarly 2 character country code :- can be interpreted as regex pattern for city code.\n",
        "d. Enter number code of the description:- check description to find out allowable code value\n",
        " usually 1-n function will be integer range checker which takes two additional parameter of min and max\n",
        "e. one of the given 1.value 2.value1 3.value2 4.value3 so our function will take list of allowed value\n",
        "as argument and can check if it exists\n",
        "4. For many of the fields this allowed_values is same or similar hence\n",
        "it makes sense to have common function for similar validations i.e for all regex validation\n",
        "we can call regex_validator function with data and pattern as parameter.\n",
        "5.You are writing in new file. At first you don't have any function so\n",
        "you have to generate a function with relevan imports to validate that requirements.\n",
        "Keep the funciton simple enough so that other similar reuirements can be validated by same function\n",
        "6.Next time you can just reference the same function by name.\n",
        "7. Remember reporting is most important so your validation rules must include nice description\n",
        "which can be used to create a informed error message for the cause of failing of rule.\n",
        "8. For now you can ignore validation rules recquiring more than one field\n",
        " \"Recall memories are contextually retrieved based on the current\"\n",
        "9. Please don't write any rule which is not required\n",
        "10. Write all the rules which are required.\n",
        "11. You can retrieve context for each column separately for better context\n",
        "12. function will be called as func(value, *validation_function_argument) so make sure your validation_function_argument\n",
        "rigorously follows function signature.\n",
        "13. You can call search_recall_memories to check if such validation function is already\n",
        "generated hence just name can be provided in this case code will be null.\n",
        "14. Your code should contain only one function. Code to apply this function will\n",
        "be written later\n",
        "15.\n",
        "\" conversation:\\n{recall_memories}\\n\\n\"\n",
        "\n",
        "\"Memory Usage Guidelines:\\n\"\n",
        "            \"1. Actively use memory tools (search_recall_memories, save_recall_memory)\"\n",
        "            \" to build a comprehensive understanding of the code.\\n\"\n",
        "            \"2. Make informed suppositions and extrapolations based on stored\"\n",
        "            \" memories.\\n\"\n",
        "            \"3. Regularly reflect on past interactions to identify patterns and\"\n",
        "            \" preferences.\\n\"\n",
        "            4. Don't assume anything\n",
        "\n",
        "Input data is in csv file which will be loaded in memory as pandas data frame\n",
        "\n",
        "\n",
        "\n",
        "Output Instuction:\n",
        "***Important when you are calling tools skip these output instructions call tools***\n",
        "Output will be list\n",
        "For each rule you will output in json format :\n",
        "  rule_id: str = Field(..., description=\"Unique identifier for the validation rule\")\n",
        "    description: str = Field(..., description=\"Detailed explanation of the requirement\")\n",
        "    impacted_data_fields: List[str] = Field(..., description=\"List of affected data fields\")\n",
        "    validation_function_name: str = Field(..., description=\"Function from chat history you are using to validate this rool or function name from code if code is not null\")\n",
        "    validation_function_argument: Optional[Union[List[int], List[str]] ]  =  Field(..., description=\"Extra aruments needed for function for.eg\"\n",
        "    \"for regex validator it will be regex pattern, for range validator it will be min and max value\")\n",
        "    code: Optional[str] = Field(..., description=\"import statement and function without any main method. This function will be used later by main method\")\n",
        "eg output:\n",
        "**No reasoning is required, code should be part of code field not outside of json array, Important Follow the output json structure rigorously. Your output should be json parsable **\n",
        "{\"extracted_rules\":[{{\"rule_id\": \"rule1\", \"description\":\"impacted_data_fields\":[\"field1\", \"field2\"], \"validation_function_name\": \"func\", \"validation_function_argument\":[1,2],\"code\":\"#some_code\" }}]}\n",
        "\"\"\"),(\"placeholder\", \"{messages}\")])\n"
      ],
      "metadata": {
        "id": "OrELAavCkmxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search = TavilySearchResults(max_results=1)\n",
        "# from langchain_groq import ChatGroq\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "import time\n",
        "\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=.25,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
        "    check_every_n_seconds=0.5,  # Wake up every 100 ms to check whether allowed to make a request,\n",
        "    max_bucket_size=10,  # Controls the maximum burst size.\n",
        ")\n",
        "def parse_output(solution):\n",
        "    \"\"\"When we add 'include_raw=True' to structured output,\n",
        "    it will return a dict w 'raw', 'parsed', 'parsing_error'.\"\"\"\n",
        "\n",
        "    return solution[\"parsed\"]\n",
        "\n",
        "# model = llm = ChatGroq(\n",
        "#     model=\"gemma2-9b-it\")\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=os.environ[\"GOOGLE_API_KEY\"], rate_limiter=rate_limiter)\n",
        "# model = ChatMistralAI(\n",
        "    # model=\"mistral-large-latest\", api_key = os.environ[\"MISTRAL_API_KEY\"],rate_limiter=rate_limiter)\n",
        "tools = [save_recall_memory, search_recall_memories, search_document_context]\n",
        "tools.extend([ComplianceResponse])\n",
        "# tools.extend(registration_rules)\n",
        "# model_with_tools = code_gen_chain_prompt | model.bind_tools(tools)#.with_structured_output(ComplianceResponse), include_raw=True) | parse_output\n",
        "model_with_tools = prompt3 | model.bind_tools(tools, tool_choice=\"any\")#.with_structured_output(ComplianceResponse), include_raw=True) | parse_output\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "\n",
        "def respond(state: State):\n",
        "    # Construct the final answer from the arguments of the last tool call\n",
        "    weather_tool_call = state[\"messages\"][-1].tool_calls[0]\n",
        "    try:\n",
        "      response = ComplianceResponse(**weather_tool_call[\"args\"])\n",
        "    except Exception as e:\n",
        "      tool_message = {\n",
        "        \"type\": \"tool\",\n",
        "        \"content\": \"Parse error {} please fix it\".format(str(e)),\n",
        "        \"tool_call_id\": weather_tool_call[\"id\"],\n",
        "      }\n",
        "      return {\"final_response\": None, \"messages\": [tool_message]}\n",
        "\n",
        "    # Since we're using tool calling to return structured output,\n",
        "    # we need to add  a tool message corresponding to the WeatherResponse tool call,\n",
        "    # This is due to LLM providers' requirement that AI messages with tool calls\n",
        "    # need to be followed by a tool message for each tool call\n",
        "    tool_message = {\n",
        "        \"type\": \"tool\",\n",
        "        \"content\": \"Here is your structured response\",\n",
        "        \"tool_call_id\": weather_tool_call[\"id\"],\n",
        "    }\n",
        "    # We return the final answer\n",
        "    return {\"final_response\": response, \"messages\": [tool_message]}\n",
        "\n",
        "def agent(state: State) -> State:\n",
        "    \"\"\"Process the current state and generate a response using the LLM.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "\n",
        "    Returns:\n",
        "        schemas.State: The updated state with the agent's response.\n",
        "    \"\"\"\n",
        "    bound = model_with_tools\n",
        "    recall_str = (\n",
        "        \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
        "    )\n",
        "    prediction = bound.invoke(\n",
        "        {\n",
        "            \"messages\": state[\"messages\"],\n",
        "            \"recall_memories\": recall_str,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [prediction],\n",
        "    }\n",
        "\n",
        "\n",
        "def load_memories(state: State, config: RunnableConfig) -> State:\n",
        "    \"\"\"Load memories for the current conversation.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "        config (RunnableConfig): The runtime configuration for the agent.\n",
        "\n",
        "    Returns:\n",
        "        State: The updated state with loaded memories.\n",
        "    \"\"\"\n",
        "\n",
        "    convo_str = get_buffer_string(state[\"messages\"])\n",
        "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
        "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
        "    # print(f\"RecallMemories:- {recall_memories}\")\n",
        "    return {\n",
        "        \"recall_memories\": recall_memories,\n",
        "    }\n",
        "\n",
        "\n",
        "def route_tools(state: State):\n",
        "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "\n",
        "    Returns:\n",
        "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
        "    \"\"\"\n",
        "    # time.sleep(3)\n",
        "    msg = state[\"messages\"][-1]\n",
        "    print(msg.tool_calls)\n",
        "    if (\n",
        "      len(msg.tool_calls) == 1\n",
        "      and msg.tool_calls[0][\"name\"] == \"ComplianceResponse\"\n",
        "  ):\n",
        "        return \"respond\"\n",
        "    if msg.tool_calls:\n",
        "        # print(msg.tool_calls)\n",
        "        return \"tools\"\n",
        "\n",
        "    # elif parse_message(msg)==False:\n",
        "    #     return \"parseerror\"\n",
        "    return \"agent\"\n",
        "\n",
        "def route_tools1(state: State):\n",
        "    if state[\"final_response\"]:\n",
        "      return END\n",
        "    return \"agent\"\n",
        "\n",
        "# def solve_parse_error(state: State):\n",
        "\n",
        "#     return {\"messages\": [(\"user\",\n",
        "#     \"If you want to give final response to user make sure your response should only contain json schema as provided in prompt.\"\n",
        "#     \"Your response should start with [ begining of list and end with ] end of list.\"\n",
        "#     \" Each item of thsi list is validation rule in json format\"\n",
        "#     \"there should not be any extra text\")]}"
      ],
      "metadata": {
        "id": "RV6JzkQtkwWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph():\n",
        "    # Create the graph and add nodes\n",
        "    builder = StateGraph(State)\n",
        "    builder.add_node(load_memories)\n",
        "    builder.add_node(agent)\n",
        "    builder.add_node(\"tools\", ToolNode(tools))\n",
        "    builder.add_node(\"respond\", respond)\n",
        "\n",
        "    # Add edges to the graph\n",
        "    builder.add_edge(START, \"load_memories\")\n",
        "    builder.add_edge(\"load_memories\", \"agent\")\n",
        "    builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", \"agent\", \"respond\"])#, \"parseerror\"])\n",
        "    builder.add_edge(\"tools\", \"agent\")\n",
        "    builder.add_conditional_edges(\"respond\", route_tools1, [END, \"agent\"])\n",
        "    # builder.add_edge(\"parseerror\", \"agent\")\n",
        "    # Compile the graph\n",
        "    memory = MemorySaver()\n",
        "    return builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "iIUeB8JDk2ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_core import from_json\n",
        "import unicodedata\n",
        "\n",
        "def extract_response(text: str) -> ComplianceResponse|None:\n",
        "    \"\"\"Extracts JSON content from a string wrapped with ```json...```\"\"\"\n",
        "    try:\n",
        "        json_str = \"{\\\"extracted_rules\\\":\" + text+ \"}\"\n",
        "      # json_str = re.sub(r\"\\\\n\", \"\\n\", json_str)\n",
        "      # json_str = \"\".join(ch for ch in json_str if unicodedata.category(ch)[0]!=\"C\")\n",
        "        return ComplianceResponse.model_validate(from_json(json_str))  # Convert string to dict\n",
        "    except:\n",
        "        print(f\"Failed to parse :- {text}\")\n",
        "        return None\n",
        "\n",
        "all_rule = ComplianceResponse(extracted_rules=[])\n",
        "\n",
        "def parse_message(message)->bool:\n",
        "    response_obj = extract_response(message.content)\n",
        "    if response_obj is None:\n",
        "        return False\n",
        "    all_rule.extracted_rules.extend(response_obj.extracted_rules)\n",
        "    return True\n",
        "def pretty_print_stream_chunk(chunk):\n",
        "    for node, updates in chunk.items():\n",
        "        print(f\"Update from node: {node}\")\n",
        "        if \"messages\" in updates:\n",
        "            updates[\"messages\"][-1].pretty_print()\n",
        "        else:\n",
        "            print(updates)\n",
        "\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "ZQXNO-N2k6eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Field for corporate loan schedule InternalObligor\n",
        "ID, CustomerID, OriginalInternalObligorID, ObligorName, City"
      ],
      "metadata": {
        "id": "scLgEolVBAwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields =[]\n",
        "with open('temp.txt', 'r') as f:\n",
        "    fields = f.readlines()\n",
        "fields = list(filter(lambda y: y!= 'DONOTUSE', map(lambda x: x.strip(), fields)))"
      ],
      "metadata": {
        "id": "Iv918l9sKqq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}, \"recursion_limit\":50}\n",
        "vectorstore = vecstore\n",
        "graph = get_graph()\n",
        "step = 7\n",
        "my_rules = ComplianceResponse(extracted_rules=[])\n",
        "for i in range(0, 20, step):\n",
        "    message = \"Field for corporate loan schedule {}\".format(', '.join(fields[i:i+step]))\n",
        "    print(f\"{message}\")\n",
        "    state = graph.invoke({\"messages\": [(\"user\", message)], \"recall_memories\" :[]\n",
        "                          }, config=config)\n",
        "    response = state['messages'][-1]\n",
        "    time.sleep(2)\n",
        "    # print(response)\n",
        "    # for chunk in graph.stream({\"messages\": [(\"user\", message)]}, config=config):\n",
        "    #     pretty_print_stream_chunk(chunk)\n",
        "# message = \"Field for corporate loan schedule {}\".format(', '.join(fields[0:5]))\n",
        "# graph.invoke({\"messages\": [(\"user\", message)], \"recall_memories\" :[]}, config=config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "obg2ipr4lWdy",
        "outputId": "e72420a6-7747-48c0-ff02-602ae320adcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Field for corporate loan schedule CustomerID, InternalObligorID, OriginalInternalObligorID, ObligorName, City, Country, ZipCodeForeignMailingCode\n",
            "[{'name': 'search_document_context', 'args': {'query': 'CustomerID allowed values', 'numberoffields': 1.0}, 'id': 'd0043b72-9424-4099-80e9-76c071f9be4d', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'InternalObligorID allowed values', 'numberoffields': 1.0}, 'id': 'ea1b1d3e-c35e-42b4-8f4f-ed4746846eee', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'OriginalInternalObligorID allowed values', 'numberoffields': 1.0}, 'id': '4947ea13-ca46-4d24-b82e-d5581d66a1ed', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'ObligorName allowed values', 'numberoffields': 1.0}, 'id': '40da0982-3707-4d95-b72b-0369134b8dfa', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'City allowed values', 'numberoffields': 1.0}, 'id': 'e8f3d540-23d4-49bf-9b45-2bdf7c138219', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'Country allowed values', 'numberoffields': 1.0}, 'id': '8accbbb4-7b07-4feb-ad51-73f059c87c14', 'type': 'tool_call'}]\n",
            "[{'name': 'search_document_context', 'args': {'query': 'ZipCodeForeignMailingCode allowed values', 'numberoffields': 1.0}, 'id': 'c5f7d764-a243-4a8c-aa43-517b2c75fd06', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': '206e1126-95c4-4595-902b-27cedeb11978', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': 'c2f5f6a7-e23c-492a-8fd7-91258ed80da2', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': '7656f56a-8bab-4c92-a32e-82fe53c12ab5', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': '334e28d3-adb0-409b-9a8b-195486c5c820', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': 'd725bd26-172f-4e48-ada6-38353be3ef84', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': '22b82533-cabd-427f-a3ae-8d50cb40ce5e', 'type': 'tool_call'}]\n",
            "[{'name': 'ComplianceResponse', 'args': {'extracted_rules': [{'validation_function_name': 'matches_pattern', 'field_name': 'CustomerID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'InternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'OriginalInternalObligorID'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ObligorName'}, {'validation_function_name': 'matches_pattern', 'field_name': 'City'}, {'validation_function_name': 'matches_pattern', 'field_name': 'Country'}, {'validation_function_name': 'matches_pattern', 'field_name': 'ZipCodeForeignMailingCode'}]}, 'id': '200ff9b9-0823-4d5c-92d6-d56e24afdac5', 'type': 'tool_call'}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-eca4c79c9c6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Field for corporate loan schedule {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{message}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     state = graph.invoke({\"messages\": [(\"user\", message)], \"recall_memories\" :[] \n\u001b[0m\u001b[1;32m     11\u001b[0m                           }, config=config)\n\u001b[1;32m     12\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2683\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2684\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2329\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2332\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 )\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-0d137e5b9f28>\u001b[0m in \u001b[0;36magent\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"<recall_memory>\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recall_memories\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n</recall_memory>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 71\u001b[0;31m     prediction = bound.invoke(\n\u001b[0m\u001b[1;32m     72\u001b[0m         {\n\u001b[1;32m     73\u001b[0m             \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3025\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3026\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5356\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5357\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5358\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5359\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         return cast(\n\u001b[1;32m    306\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    842\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 results.append(\n\u001b[0;32m--> 683\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    684\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# we do want to rate limit API requests.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;31m# If stream is not explicitly set, check if implicitly requested by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/rate_limiters.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, blocking)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_every_n_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_rules = ComplianceResponse(extracted_rules=[])\n",
        "message = \"Field for corporate loan schedule Country, City, OriginationDate, MaturityDate, FacilityType\"\n",
        "state = graph.invoke({\"messages\": [(\"user\", message)], \"recall_memories\" :[]}, config=config)"
      ],
      "metadata": {
        "id": "ubhk6FU6OaTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('validation', 'w') as f:\n",
        "  f.write(my_rules.model_dump_json())"
      ],
      "metadata": {
        "id": "bZpg6WC6nM06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state"
      ],
      "metadata": {
        "id": "nXzlZgRBzDiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(filter(lambda x:x.code,all_rule.extracted_rules))[0].code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ejIbl2JYPZh",
        "outputId": "55be4138-7515-4dbd-e1a5-a9166d7a6f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import re\n",
            "\n",
            "def regex_validator(data, patterns):\n",
            "    \"\"\"\n",
            "    Validate data against a list of regex patterns.\n",
            "    \"\"\"\n",
            "    for pattern in patterns:\n",
            "        if re.fullmatch(pattern, data):\n",
            "            return True\n",
            "    return False\n",
            "\n",
            "# Example usage\n",
            "# data = \"123456\"  # Example data to validate\n",
            "# patterns = [\"^\\d{4,6}$\", \"^\\d{2,4}$\", \"^[A-Z0-9]{6}$\"]  # List of regex patterns\n",
            "# is_valid = regex_validator(data, patterns)\n",
            "# print(is_valid)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_match = re.search(r\"```json([\\w\\W]*)```\", response.content, re.DOTALL)\n",
        "# print(_match)\n",
        "if _match:\n",
        "    json_str = \"{\\\"extracted_rules\\\":\" + format(_match.group(1)) + \"}\"\n",
        "    json_str = re.sub(r\"\\\\n\", \"\\n\", json_str)\n",
        "    json_str = \"\".join(ch for ch in json_str if ch=='\\n' or unicodedata.category(ch)[0]!=\"C\" )\n",
        "from_json(json_str)\n",
        "# from_json('{\"testing\": \"\"\"assert date_validator(\\\"2005-02-01\\\", \\\"%Y-%m-%d\\\") == True\"\"\"  }')"
      ],
      "metadata": {
        "id": "X6wZdDqgBsAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unicodedata.category('\\n')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hWYht6VyqHXv",
        "outputId": "d2779d8b-7f50-49ad-dc93-113abbf9d4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'{\"testing\": \"\"\"assert date_validator(\\\"2005-02-01\\\", \\\"%Y-%m-%d\\\") == True\"\"\"  }'[14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Vn1QWh0ZLS7",
        "outputId": "f3f1b4ce-6256-43a8-cc73-7299db944168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_document_context(\"ParticipationFlag\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoFwrQYA4XkI",
        "outputId": "597e7a7f-9374-4aa7-c05c-c4a62c9ff4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in graph.stream({\"messages\": [(\"user\", \"Can you print out what context did you get from search_document_context\")]}, config=config):\n",
        "    pretty_print_stream_chunk(chunk)\n",
        "# graph.invoke({\"messages\": [(\"user\", \"Field for corporate loan schedule column LineReportedOnFRY9C:- allowed_values Enter number code of the description\")], \"recall_memories\" :[]}, config=config)[\"messages\"][-1].content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ9SoBHKaOwf",
        "outputId": "f1f93574-405d-4fbd-c89e-38ecb1101355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node: load_memories\n",
            "{'recall_memories': []}\n",
            "\n",
            "\n",
            "Update from node: agent\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I apologize, but I cannot directly access or print the context retrieved from the `search_document_context` tool.  That's because I'm designed to only use the available tools and libraries within the given context, and I don't have the capability to display the internal workings or outputs of those tools directly.  I can only use their results to generate code and answer your questions.\n",
            "\n",
            "When I called `search_document_context`, I didn't receive specific content about the `ParticipationFlag` field that I could display to you.  My response about it having allowed values 'Y' and 'N' was a reasoned assumption based on common data reporting practices and similar field names.  To generate more accurate validation rules, I need the actual content of the relevant regulatory documents or the explicit allowed values for the field.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import get_buffer_string\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.constants import END, START\n",
        "from langgraph.graph import MessagesState, StateGraph\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Union, Annotated\n",
        "\n",
        "\n",
        "\n",
        "# Data model\n",
        "class ValidationRule(BaseModel):\n",
        "    description: str = Field(..., description=\"Detailed explanation of the requirement\")\n",
        "    field_name: str = Field(..., description=\"field name\")\n",
        "    validation_function_name: str = Field(...,\n",
        "                                          description=\"Function from chat history which can be used for this or generated\"\n",
        "                                                      \"function name from code\")\n",
        "    arguments: Optional[Union[List[int], List[str], List[List[str]]]] = Field(...,\n",
        "                                                                              description=\"Extra aruments needed for function for.eg\"\n",
        "                                                                                          \"for regex validator it will be regex pattern, for range validator it will be min and max value\")\n",
        "    code: Optional[str] = Field(None,\n",
        "                                description=\"import statement and function without any main method. This function will be used later by main method\")\n",
        "\n",
        "\n",
        "class ComplianceResponse(BaseModel):\n",
        "    \"\"\"Respond to the user with this\"\"\"\n",
        "    extracted_rules: List[ValidationRule] = Field(..., description=\"List of extracted data validation rules\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_recall_memory(memory: str) -> str:\n",
        "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
        "    # user_id = get_user_id(config)\n",
        "    document = Document(\n",
        "        page_content=memory, metadata={\"source\": \"history\"}, id=str(uuid.uuid4())  # , metadata={\"user_id\": user_id}\n",
        "    )\n",
        "    vecstore.add_documents([document])\n",
        "    return memory\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_recall_memories(query: str) -> List[str]:\n",
        "    \"\"\"Search for relevant memories.\"\"\"\n",
        "\n",
        "    # user_id = get_user_id(config)\n",
        "\n",
        "    def _filter_function(metadata) -> bool:\n",
        "        return metadata.get(\"source\") == \"history\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=3, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_document_context(query: str) -> List[str]:\n",
        "    \"\"\"Search for relevant context from regulatory documents.\"\"\"\n",
        "\n",
        "    def _filter_function(metadata) -> bool:\n",
        "        return metadata.get(\"source\") == \"table\"\n",
        "\n",
        "    documents = vecstore.similarity_search(\n",
        "        query, k=10, filter=_filter_function\n",
        "    )\n",
        "    return [document.page_content for document in documents]\n",
        "\n",
        "\n",
        "class State(MessagesState):\n",
        "    # add memories that will be retrieved based on the conversation context\n",
        "    recall_memories: List[str]\n",
        "\n",
        "\n",
        "def agent(state: State) -> State:\n",
        "    \"\"\"Process the current state and generate a response using the LLM.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "\n",
        "    Returns:\n",
        "        schemas.State: The updated state with the agent's response.\n",
        "    \"\"\"\n",
        "    bound = model_with_tools\n",
        "    recall_str = (\n",
        "            \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
        "    )\n",
        "    prediction: ComplianceResponse = bound.invoke(\n",
        "        {\n",
        "            \"messages\": state[\"messages\"],\n",
        "            \"recall_memories\": recall_str,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [prediction],\n",
        "    }\n",
        "\n",
        "\n",
        "def load_memories(state: State, config: RunnableConfig) -> State:\n",
        "    \"\"\"Load memories for the current conversation.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "        config (RunnableConfig): The runtime configuration for the agent.\n",
        "\n",
        "    Returns:\n",
        "        State: The updated state with loaded memories.\n",
        "    \"\"\"\n",
        "\n",
        "    convo_str = get_buffer_string(state[\"messages\"])\n",
        "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
        "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
        "    # print(f\"RecallMemories:- {recall_memories}\")\n",
        "    return {\n",
        "        \"recall_memories\": recall_memories,\n",
        "    }\n",
        "\n",
        "\n",
        "from pydantic_core import from_json\n",
        "\n",
        "\n",
        "def extract_response(text: str) -> ComplianceResponse | None:\n",
        "    \"\"\"Extracts JSON content from a string wrapped with ```json...```\"\"\"\n",
        "    try:\n",
        "        json_str = \"{\\\"extracted_rules\\\":\" + text + \"}\"\n",
        "        # json_str = re.sub(r\"\\\\n\", \"\\n\", json_str)\n",
        "        # json_str = \"\".join(ch for ch in json_str if unicodedata.category(ch)[0]!=\"C\")\n",
        "        return ComplianceResponse.model_validate(from_json(json_str))  # Convert string to dict\n",
        "    except:\n",
        "        print(f\"Failed to parse :- {text}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def parse_message(message) -> bool:\n",
        "    response_obj = extract_response(message.content)\n",
        "    if response_obj is None:\n",
        "        return False\n",
        "    # all_rule.extracted_rules.extend(response_obj.extracted_rules)\n",
        "    return True\n",
        "\n",
        "\n",
        "def route_tools(state: State):\n",
        "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
        "\n",
        "    Args:\n",
        "        state (schemas.State): The current state of the conversation.\n",
        "\n",
        "    Returns:\n",
        "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
        "    \"\"\"\n",
        "    msg = state[\"messages\"][-1]\n",
        "    if msg.tool_calls:\n",
        "        return \"tools\"\n",
        "    # elif parse_message(msg) == False:\n",
        "    #     return \"parseerror\"\n",
        "    return END\n",
        "\n",
        "\n",
        "def get_graph():\n",
        "    # Create the graph and add nodes\n",
        "    builder = StateGraph(State)\n",
        "    builder.add_node(load_memories)\n",
        "    builder.add_node(agent)\n",
        "    tools = [save_recall_memory, search_recall_memories, search_document_context]\n",
        "    builder.add_node(\"tools\", ToolNode(tools))\n",
        "    # builder.add_node(\"parseerror\", solve_parse_error)\n",
        "    # Add edges to the graph\n",
        "    builder.add_edge(START, \"load_memories\")\n",
        "    builder.add_edge(\"load_memories\", \"agent\")\n",
        "    builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", \"agent\", END])\n",
        "    builder.add_edge(\"tools\", \"agent\")\n",
        "    # builder.add_edge(\"parseerror\", \"agent\")\n",
        "    # Compile the graph\n",
        "    memory = MemorySaver()\n",
        "    return builder.compile(checkpointer=memory)\n",
        "\n",
        "\n",
        "def generate_rules(fields: List[str]):\n",
        "    global my_rules\n",
        "    my_rules = ComplianceResponse(extracted_rules=[])\n",
        "    config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}, \"recursion_limit\": 100}\n",
        "    graph = get_graph()\n",
        "    step = 7\n",
        "\n",
        "    for i in range(0, len(fields), step):\n",
        "        message = \"Field for corporate loan schedule {}\".format(', '.join(fields[i:i + step]))\n",
        "        print(f\"{message}\")\n",
        "        graph.invoke({\"messages\": [(\"user\", message)], \"recall_memories\": []}, config=config)\n",
        "        time.sleep(2)\n",
        "    return my_rules\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_integer(field_name: str, description: Annotated[str, \"description of the rule\"]) -> str:\n",
        "    \"\"\"Regester integer check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name,\n",
        "                                                   description=description, validation_function_name=\n",
        "                                                   \"is_integer\"))\n",
        "\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_integer.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_whole_number(field_name: str, description: str) -> str:\n",
        "    \"\"\"Register whole number check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                   validation_function_name=\n",
        "                                                   \"is_whole_number\"))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function  is_whole_number.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_in_range(field_name: str, description: str, min_v: int, max_v: int) -> str:\n",
        "    \"\"\"Register whole number check for field_name\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                   validation_function_name=\n",
        "                                                   \"is_in_range\", arguments=[min_v, max_v]))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function  is_in_range.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def matches_pattern(field_name: str, description: str, pattern: List[str]) -> str:\n",
        "    \"\"\"Register regex pattern check \"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                   validation_function_name=\n",
        "                                                   \"matches_pattern\", arguments=[pattern]))\n",
        "    print(my_rules.extracted_rules)\n",
        "    return f\"Successfully registered rule for {field_name} with validation function matches_pattern.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_in_list(field_name: str, description: str, allowed_values: List[str]) -> str:\n",
        "    \"\"\"Register is in list check\"\"\"\n",
        "    my_rules.extracted_rules.append(ValidationRule(field_name=field_name, description=description,\n",
        "                                                   validation_function_name=\n",
        "                                                   \"is_in_list\", arguments=[allowed_values]))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_in_list.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def is_valid_date(field_name: str, description: str, format: str) -> str:\n",
        "    \"\"\"Register is valid date format check\"\"\"\n",
        "    my_rules.extracted_rules.append(\n",
        "        ValidationRule(field_name=field_name, description=description, validation_function_name=\n",
        "        \"is_valid_date\"))\n",
        "    return f\"Successfully registered rule for {field_name} with validation function is_valid_date. \"\n",
        "\n",
        "\n",
        "registration_rules = [is_integer, is_in_list, is_whole_number, is_valid_date,\n",
        "                      matches_pattern, is_in_range]\n",
        "\n",
        "\n",
        "def solve_parse_error(state: State):\n",
        "    return {\"messages\": [(\"user\", \"You should have invoked tools instead of giving json repsonse\")]}\n",
        "\n",
        "\n",
        "# getApiKey()\n",
        "\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=.25,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
        "    check_every_n_seconds=0.5,  # Wake up every 100 ms to check whether allowed to make a request,\n",
        "    max_bucket_size=10,  # Controls the maximum burst size.\n",
        ")\n",
        "# model = ChatMistralAI(\n",
        "#     model=\"mistral-large-latest\", api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
        "                               rate_limiter=rate_limiter)\n",
        "\n",
        "my_rules = ComplianceResponse(extracted_rules=[])\n",
        "tools = [save_recall_memory, search_recall_memories, search_document_context]\n",
        "tools.extend(registration_rules)\n",
        "model_with_tools = code_ge_prompt_with_tools_to_register_rules | model.bind_tools(tools)\n"
      ],
      "metadata": {
        "id": "gkM1Q2do0Abe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_rules([\"Country\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQeE6KPUvmc_",
        "outputId": "348c77c7-ceeb-4c23-c963-2b4c018a2261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Field for corporate loan schedule Country\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplianceResponse(extracted_rules=[])"
            ]
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2PZfsbrv0E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}